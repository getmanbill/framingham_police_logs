{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "I'd like to get a better understanding of crime in my neighborhood, but the publicly available information only comes in pdf form. The purpose of this script is to take pdfs downloaded from the Framingham police department, and transform the files into usable data points for analysis.\n",
    "\n",
    "Website: https://www.framinghamma.gov/DocumentCenter/Home/Index/149\n",
    "\n",
    "1. Functions\n",
    "    - split_types: regex functions that find the line breaks in uploaded text\n",
    "    - police_log_day: \n",
    "        - loads pdfs one day at a time\n",
    "        - loops through all the days in a pdf\n",
    "        - returns a dataframe with all the pages split into individual logs\n",
    "1. Load data: Loops through all the pdfs in a local folder. Future iterations might automatically scrape the info off the web.\n",
    "1. lat_lon Function: taps the googlemaps api to get latitude and longitude for a given address\n",
    "1. Apply the lat_lon function to the data set\n",
    "1. Save the data to a .csv -- a secondary script saves that file into a local postgres database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "import requests\n",
    "\n",
    "endpoint = 'https://maps.googleapis.com/maps/api/geocode/json?'\n",
    "api_key = input()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below takes a single pdf, loops through each page, and splits the text into distinct rows. \n",
    "\n",
    "Then it returns a combined dataframe with the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def police_log_day(file):\n",
    "    #function returns parsed list from individual calls\n",
    "    def split_types(text, time):\n",
    "        time = time\n",
    "        start = text.find(time_match[0])\n",
    "        rest = text[start + len(time):]\n",
    "        colon = rest.find(':')\n",
    "        call_type = rest[:colon].lstrip().rstrip()\n",
    "        rest = rest[colon+2:]\n",
    "        paren_open = rest.find('(')\n",
    "        paren_close = rest.find(')')\n",
    "        note = rest[paren_open+1:paren_close]\n",
    "        address = rest[:paren_open].lstrip().rstrip()\n",
    "\n",
    "        return [time, call_type, note, address]\n",
    "    \n",
    "\n",
    "    file = file\n",
    "    rough_date = file[-14:-4]\n",
    "    year = rough_date[:4]\n",
    "    month = rough_date[5:7]\n",
    "    day = rough_date[-2:]\n",
    "    \n",
    "    pdfReader = PyPDF2.PdfFileReader(open(file, 'rb'))\n",
    "    num_pages = pdfReader.numPages\n",
    "    \n",
    "    #read and combine all the pages of text into a single string\n",
    "    text = ''\n",
    "    \n",
    "    for page in range(num_pages):\n",
    "        pageObj = pdfReader.getPage(page)\n",
    "        text = text + pageObj.extractText()\n",
    "    time_pattern = r'[0-9][0-9]:[0-9][0-9]'\n",
    "    num_pattern = r'[0-9]{7}'\n",
    "    \n",
    "\n",
    "    split_text = text.split('\\n\\n')\n",
    "    calls = []\n",
    "    for i in split_text:\n",
    "        i_adj = re.sub(num_pattern,'', i)\n",
    "        time_match = re.findall(time_pattern, i_adj)\n",
    "        if len(time_match) == 1 and 'Page:' not in i_adj:\n",
    "            calls.append(split_types(i_adj,time_match[0]))\n",
    "        elif len(time_match) == 0:\n",
    "            pass\n",
    "        elif 'Page:' not in i_adj:\n",
    "            for num, time in enumerate(time_match):\n",
    "                calls.append(split_types(i_adj,time))  \n",
    "\n",
    "    data = pd.DataFrame(calls, columns= ['Time','Type','Note','Address'])\n",
    "    data['date'] = '{}/{}/{}'.format(year,month,day)\n",
    "    data['load_date'] = dt.datetime.now()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below loops through all the pdfs in a local folder, then concatenates all the outputs to a signle dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/Users/williamgetman/Dropbox/Python/Police Logs/raw_data/'\n",
    "folders_in_log = os.listdir(folder)\n",
    "\n",
    "all_data = pd.DataFrame(columns = ['Time','Type','Note','Address','date','load_date'])\n",
    "for file in folders_in_log:\n",
    "    file_name = folder + file\n",
    "    df = police_log_day(file_name)\n",
    "    all_data = pd.concat([all_data, df], axis=0, join='outer',ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below pings the googlemaps api and returns latitude and longitude for a given Framingham address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lat_lon(address):\n",
    "    address = address + ' Framingham, MA 01702'\n",
    "    address = address.lower()\n",
    "\n",
    "    url_address = address.replace(' ','+')\n",
    "    lat_lng = []\n",
    "    nav_request = 'address={}&key={}'.format(url_address,api_key)\n",
    "    \n",
    "    request = endpoint + nav_request\n",
    "    response = requests.get(request)\n",
    "    \n",
    "    resp_json_payload = response.json()\n",
    "    for item in resp_json_payload['results']:\n",
    "        for key,detail_item in item['geometry']['location'].items():\n",
    "            if key == 'lat' and len(lat_lng) < 2:\n",
    "                lat_lng.append(detail_item)\n",
    "            elif key == 'lng' and len(lat_lng) < 2:\n",
    "                lat_lng.append(detail_item)\n",
    "    return lat_lng\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below applies the lat_lon function to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lat_long = all_data.copy()\n",
    "data_lat_long['lat_long'] = data_lat_long['Address'].apply(lat_lon)\n",
    "data_lat_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lat_long.to_csv('/Users/williamgetman/Dropbox/Python/Police Logs/all_data.w.address.11.3.19.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
